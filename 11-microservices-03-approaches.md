# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

## ОТВЕТ 1
Задача 1: Обеспечить разработку (CI/CD)
Решение:
Использование GitLab SaaS или GitLab Self-Managed (облачная система + возможность установки агентов на своих серверах).
Система контроля версий — GitLab поддерживает Git, каждый сервис хранится в отдельном репозитории.
CI/CD:
Запуск сборки по событию (push/merge request).
Ручной запуск по кнопке с параметрами (pipeline variables).
Настройки и шаблоны сборок можно вынести в .gitlab-ci.yml и общие include-файлы.
Поддержка секретов через GitLab CI/CD Variables, Vault integration.
Поддержка нескольких конфигураций сборок (staging, production, custom branches).
Возможность добавлять кастомные шаги и использовать свои Docker-образы.
Возможность запуска агентов сборки как в облаке, так и на собственных серверах (GitLab Runners).
Поддержка параллельных сборок и тестов (matrix jobs, parallelization).

Альтернативы:
GitHub + GitHub Actions (также полностью покрывает требования).
Jenkins + GitHub/GitLab/Bitbucket — более гибко, но требует больше ручной поддержки.
Почему GitLab?
Полный DevOps-комплекс: Git, CI/CD, контейнерный реестр, управление секретами.
Есть облачный вариант и возможность хостить у себя.
Хорошая поддержка Kubernetes и Docker.

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

## ОТВЕТ 2

Решение:
Использование ELK-стека (Elasticsearch + Logstash/Fluentd + Kibana) или EFK (Elasticsearch + Fluentd + Kibana).
Сбор логов:
Приложения пишут в stdout.
Агент (Fluentd/Fluent Bit) собирает логи с хостов.
Гарантированная доставка:
Используется промежуточный буфер (Kafka или встроенные механизмы Fluentd).
Централизованное хранилище: Elasticsearch.
Поиск и фильтрация: Kibana с удобным UI.
Доступ разработчикам: через Kibana можно выдать доступ на чтение.
Сохранённые поиски: Kibana позволяет создавать дашборды и сохранять поисковые запросы с возможностью делиться ссылками.
Альтернативы:
Grafana Loki + Promtail + Grafana — более дешёвое решение (лучше по ресурсам, чем ELK).
Datadog Logs / Splunk — SaaS-решения, удобны, но дороже.
Почему EFK?
Де-факто стандарт в микросервисной архитектуре.
Подходит для Kubernetes и bare-metal.
Легко расширяемо и интегрируется с мониторингом.



## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

## ОТВЕТ 3
Решение:
Использование Prometheus + Grafana.
Сбор метрик:
Node Exporter для CPU, RAM, HDD, Network с хостов.
cAdvisor для метрик контейнеров (CPU, RAM, Network per service).
Сервисы отдают метрики через /metrics (Prometheus client libs).
Агрегация и запросы: Prometheus Query Language (PromQL).
UI и дашборды: Grafana:
Построение панелей для состояния системы.
Агрегация по сервисам и хостам.
Возможность делиться ссылками на дашборды.
Альтернативы:
Zabbix (классическая система мониторинга, больше для инфраструктуры).
Datadog / NewRelic (SaaS, платные).
Почему Prometheus + Grafana?
Open-source, активно развивается, интегрируется с Kubernetes и Docker.
Удобный UI для разработчиков и админов.
Гибкий язык запросов (PromQL).
Отлично масштабируется и легко настраивается.



## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
